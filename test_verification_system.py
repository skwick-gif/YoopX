"""
Comprehensive test of the enhanced verification system for ML/Backtest/Optimize/Scanner compatibility.
"""

import sys
import os
sys.path.append('.')

from data.data_paths import get_data_paths
from data.enhanced_verification import verify_processed_data_structure
import json


def test_verification_system():
    """Test the enhanced verification system."""
    print("=" * 80)
    print("ğŸ” ENHANCED DATA VERIFICATION SYSTEM TEST")
    print("=" * 80)
    print()
    
    print("ğŸ¯ **××” ×”×•×•×¨×™×¤×™×§×¦×™×” ×‘×•×“×§×ª ×¢×‘×•×¨ ML/Backtest/Optimize/Scanner:**")
    print()
    
    print("ğŸ“‹ **1. STRUCTURE VERIFICATION:**")
    print("   âœ… Directory structure: processed_data/_parquet/ & _catalog/")
    print("   âœ… File existence: Parquet files + catalog.json + catalog.parquet")
    print("   âœ… File counts match between directories")
    print()
    
    print("ğŸ“Š **2. DATA COMPATIBILITY:**")
    print("   ğŸ¤– **ML Module**: Open, High, Low, Close, Volume, date + sufficient history")
    print("   ğŸ“ˆ **Backtest Module**: OHLCV columns + proper date index/column")
    print("   âš™ï¸ **Optimize Module**: Same as Backtest (parameter optimization)")
    print("   ğŸ” **Scanner Module**: Same as Backtest (pattern scanning)")
    print()
    
    print("ğŸ” **3. DATA QUALITY CHECKS:**")
    print("   ğŸ“… Date consistency and recent data")
    print("   ğŸ“Š Column presence and data types")
    print("   ğŸ“ˆ Sufficient data rows for analysis")
    print("   ğŸš« No corruption or read errors")
    print()
    
    print("ğŸ“š **4. CATALOG INTEGRITY:**")
    print("   ğŸ“„ Catalog JSON structure and completeness")
    print("   ğŸ“¦ Catalog Parquet consistency")
    print("   ğŸ¯ Entry accuracy and metadata")
    print()
    
    # Run actual verification
    paths = get_data_paths()
    processed_dir = paths['processed']
    
    print(f"ğŸ” **Running verification on: {processed_dir}**")
    print()
    
    try:
        verification_report = verify_processed_data_structure(processed_dir)
        
        print("ğŸ“‹ **VERIFICATION RESULTS:**")
        print("=" * 50)
        
        # Structure Check
        structure = verification_report.get('structure_check', {})
        print(f"ğŸ—ï¸  **Structure Check**: {'âœ… PASS' if structure.get('is_valid') else 'âŒ FAIL'}")
        print(f"   â€¢ Base directory exists: {structure.get('base_dir_exists')}")
        print(f"   â€¢ Parquet directory exists: {structure.get('parquet_dir_exists')}")
        print(f"   â€¢ Catalog directory exists: {structure.get('catalog_dir_exists')}")
        print(f"   â€¢ Parquet files found: {structure.get('parquet_files_count', 0)}")
        print()
        
        # Catalog Check
        catalog = verification_report.get('catalog_check', {})
        print(f"ğŸ“š **Catalog Check**: {'âœ… PASS' if catalog.get('is_valid') else 'âŒ FAIL'}")
        print(f"   â€¢ Catalog JSON exists: {catalog.get('catalog_json_exists')}")
        print(f"   â€¢ Catalog Parquet exists: {catalog.get('catalog_parquet_exists')}")
        print(f"   â€¢ Entries count: {catalog.get('entries_count', 0)}")
        print(f"   â€¢ JSON-Parquet match: {catalog.get('json_parquet_match')}")
        if catalog.get('issues'):
            for issue in catalog['issues']:
                print(f"   âš ï¸  Issue: {issue}")
        print()
        
        # Module Compatibility  
        compatibility = verification_report.get('data_compatibility', {})
        print("ğŸ¯ **Module Compatibility:**")
        
        modules = {
            'ml_module': 'ğŸ¤– ML Module',
            'backtest_module': 'ğŸ“ˆ Backtest Module', 
            'optimize_module': 'âš™ï¸ Optimize Module',
            'scanner_module': 'ğŸ” Scanner Module'
        }
        
        for module_key, module_name in modules.items():
            module_info = compatibility.get(module_key, {})
            compatible = module_info.get('compatible', False)
            issues = module_info.get('issues', [])
            
            status = 'âœ… COMPATIBLE' if compatible else 'âŒ INCOMPATIBLE'
            print(f"   {module_name}: {status}")
            
            if issues:
                for issue in issues:
                    print(f"     âš ï¸  {issue}")
        
        data_map_ok = compatibility.get('data_map_loadable', False)
        print(f"   ğŸ“Š Data Map Loadable: {'âœ… YES' if data_map_ok else 'âŒ NO'}")
        print()
        
        # Summary
        summary = verification_report.get('summary', {})
        print("ğŸ“Š **SUMMARY:**")
        print(f"   â€¢ Total tickers checked: {summary.get('total_tickers', 0)}")
        print(f"   â€¢ âœ… Verified tickers: {summary.get('verified_tickers', 0)}")
        print(f"   â€¢ âš ï¸  Warning tickers: {summary.get('warning_tickers', 0)}")
        print(f"   â€¢ âŒ Failed tickers: {summary.get('failed_tickers', 0)}")
        print()
        
        # Recommendations
        recommendations = verification_report.get('recommendations', [])
        if recommendations:
            print("ğŸ’¡ **RECOMMENDATIONS:**")
            for rec in recommendations:
                print(f"   {rec}")
            print()
        
        # Overall Status
        total = summary.get('total_tickers', 0)
        verified = summary.get('verified_tickers', 0)
        
        if total == 0:
            print("âš ï¸  **STATUS: NO DATA FOUND**")
            print("   Run Daily Update first to download and process data")
        elif verified == total:
            print("ğŸ‰ **STATUS: ALL SYSTEMS GO!**") 
            print("   âœ… Data is ready for ML, Backtest, Optimize, and Scanner!")
        else:
            failed = summary.get('failed_tickers', 0)
            if failed > 0:
                print("âš ï¸  **STATUS: ISSUES DETECTED**")
                print(f"   {failed} tickers need attention before running ML/Backtest")
            else:
                print("ğŸŸ¡ **STATUS: MOSTLY READY**")
                print("   Minor warnings present, but should work for most operations")
        
        return verification_report
        
    except Exception as e:
        print(f"âŒ **VERIFICATION ERROR**: {e}")
        print("   The verification system encountered an error")
        print("   This might indicate missing directories or corrupted data")
        return None


def demonstrate_verification_flow():
    """Demonstrate the complete verification flow."""
    print("\n" + "=" * 80) 
    print("ğŸ”„ COMPLETE DAILY UPDATE + VERIFICATION FLOW")
    print("=" * 80)
    print()
    
    print("ğŸ“‹ **×”×”×œ×™×š ×”××œ× ×©×¢×›×©×™×• ××ª×‘×¦×¢ ×‘-Daily Update:**")
    print()
    
    print("1ï¸âƒ£ **Data Download** (0-80%)")
    print("   â€¢ ğŸ“¥ Download from Yahoo Finance + API providers")
    print("   â€¢ ğŸ’¾ Save raw JSON files to raw_data/")
    print("   â€¢ ğŸ”„ Smart incremental updates")
    print()
    
    print("2ï¸âƒ£ **Data Processing** (80-95%)")
    print("   â€¢ ğŸ”„ Convert JSON to structured Parquet")
    print("   â€¢ ğŸ“Š Create standardized columns (OHLCV + metadata)")
    print("   â€¢ ğŸ“š Generate catalog for fast access")
    print()
    
    print("3ï¸âƒ£ **Automatic Verification** (95-99%)")
    print("   â€¢ ğŸ” Verify ML module compatibility")
    print("   â€¢ ğŸ“ˆ Check Backtest data requirements")
    print("   â€¢ âš™ï¸ Validate Optimize/Scanner readiness")
    print("   â€¢ ğŸ¯ Test data_map loading")
    print()
    
    print("4ï¸âƒ£ **Results & Recommendations** (100%)")
    print("   â€¢ âœ… Report compatibility status")
    print("   â€¢ ğŸ“‹ Generate detailed verification report")
    print("   â€¢ ğŸ’¡ Provide actionable recommendations")
    print()
    
    print("ğŸ¯ **×”×™×ª×¨×•×Ÿ ×”×—×“×©:**")
    print("   ×œ× ×¦×¨×™×š ×œ×—×›×•×ª ×œ××•×“×•×œ ML/Backtest ×›×“×™ ×œ×’×œ×•×ª ×©×™×© ×‘×¢×™×”!")
    print("   ×”×•×•×¨×™×¤×™×§×¦×™×” ××–×”×” ×‘×¢×™×•×ª ××™×“ ×•××¦×™×¢×” ×¤×ª×¨×•× ×•×ª.")


if __name__ == "__main__":
    report = test_verification_system()
    demonstrate_verification_flow()
    
    if report:
        print("\nğŸ‰ Verification system is working!")
    else:
        print("\nâš ï¸ Run Daily Update first to create processed data.")