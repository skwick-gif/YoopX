#!/usr/bin/env python3
"""
ğŸ”„ Iterative Historical Training System - ××™××•×© ×”×ª×”×œ×™×š ×©×”××©×ª××© ×‘×™×§×©

×ª×”×œ×™×š: 
1. ×××Ÿ ×¢×“ ×ª××¨×™×š X (30 ×™××™ ××¡×—×¨ ××—×•×¨×”)
2. ×‘×“×•×§ ×‘×™×¦×•×¢×™× ×¢×œ ×”× ×ª×•× ×™× ×©×œ× × ×›×œ×œ×• ×‘××™××•×Ÿ (×”-30 ×™××™×)
3. ×”×©×•×•×” ×ª×—×–×™×•×ª ××•×œ ××¦×™××•×ª
4. ×¢×“×›×Ÿ/×›×™×™×œ ××•×“×œ
5. ×—×–×•×¨ ×œ×©×œ×‘ 1 ×¢× × ×ª×•× ×™× ××¢×•×“×›× ×™×
6. ×”××©×š ×¢×“ ×©××’×™×¢×™× ×œ×“×™×•×§ ××§×¡×™××œ×™
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import logging
from dataclasses import dataclass

@dataclass
class IterativeTrainingConfig:
    """×”×’×“×¨×•×ª ×œ××™××•×Ÿ ×˜×™×˜×¨×˜×™×‘×™
    label_threshold: ××—×•×– ×”×ª×©×•××” ×©××’×“×™×¨ ×”×¦×œ×—×” (×“×™×¤×•×œ×˜ 2%)
    blend_alpha: ×›××” ××©×§×œ ×œ×ª×ª ×œ×“×™×•×§ ×”××©×•×§×œ×œ (0..1)
    """
    initial_lookback_days: int = 30  # ×›××” ×™××™ ××¡×—×¨ ××—×•×¨×” ×œ×”×ª×—×™×œ
    horizons: List[int] = None
    max_iterations: int = 10  # ××§×¡×™××•× ××™×˜×¨×¦×™×•×ª
    min_accuracy_improvement: float = 0.01  # ×©×™×¤×•×¨ ××™× ×™××œ×™ ×œ×—×–×•×¨ ×œ××™×˜×¨×¦×™×” ×”×‘××”
    target_accuracy: float = 0.70  # ×“×™×•×§ ×™×¢×“ ×œ×¢×¦×™×¨×”
    label_threshold: float = 0.02  # 2% ×ª×©×•××”
    blend_alpha: float = 0.40  # ××©×§×œ ×œ×“×™×•×§ ×”××©×•×§×œ×œ (×œ×©×¢×‘×¨ 0.4 ×§×‘×•×¢)
    
    def __post_init__(self):
        if self.horizons is None:
            self.horizons = [1, 5, 10]

@dataclass 
class IterativeResults:
    """×ª×•×¦××•×ª ××™×˜×¨×¦×™×”"""
    iteration: int
    training_cutoff_date: str
    validation_start_date: str
    validation_end_date: str
    models_trained: Dict[int, str]  # horizon -> model_path
    predictions: List[Dict]  # ×ª×—×–×™×•×ª
    actual_results: List[Dict]  # ×ª×•×¦××•×ª ×‘×¤×•×¢×œ
    accuracy_by_horizon: Dict[int, float]  # ×“×™×•×§ ×œ×›×œ horizon
    improvement_from_previous: Optional[float] = None

class IterativeHistoricalTrainer:
    """××¢×¨×›×ª ××™××•×Ÿ ×˜×™×˜×¨×˜×™×‘×™×ª ×”×™×¡×˜×•×¨×™×ª"""
    
    def __init__(self, data_map: Dict[str, pd.DataFrame]):
        self.data_map = data_map
        self.logger = logging.getLogger(__name__)
        self.results_history: List[IterativeResults] = []
        
        # ×ª×™×§×™×•×ª ×œ×©××™×¨×ª ××•×“×œ×™× ×•×ª×•×¦××•×ª
        self.models_dir = "ml/iterative_models"
        self.results_dir = "ml/iterative_results" 
        os.makedirs(self.models_dir, exist_ok=True)
        os.makedirs(self.results_dir, exist_ok=True)
        
    def run_iterative_training(self, config: IterativeTrainingConfig) -> List[IterativeResults]:
        """
        ×”×¨×¦×ª ×”×ª×”×œ×™×š ×”×˜×™×˜×¨×˜×™×‘×™ ×”××œ×
        
        ×–×”×• ×”×ª×”×œ×™×š ×©×”××©×ª××© ×‘×™×§×©:
        1. ×××Ÿ ×¢×œ × ×ª×•× ×™× ×¢×“ ×ª××¨×™×š X
        2. ×‘×“×•×§ ×¢×œ ×”×ª×§×•×¤×” ×©×œ× × ×›×œ×œ×” ×‘××™××•×Ÿ  
        3. ×”×©×•×•×” ×ª×—×–×™×•×ª ××•×œ ××¦×™××•×ª
        4. ×©×¤×¨ ××•×“×œ ×•×”××©×š
        """
        
        self.logger.info(f"ğŸš€ ××ª×—×™×œ ××™××•×Ÿ ×˜×™×˜×¨×˜×™×‘×™ ×¢× {config.initial_lookback_days} ×™××™ ××¡×—×¨")
        
        # ××¦×™××ª ×”×ª××¨×™×š ×”××—×¨×•×Ÿ ×‘× ×ª×•× ×™×
        latest_date = self._find_latest_date()
        if not latest_date:
            raise ValueError("×œ× × ××¦× ×ª××¨×™×š ××—×¨×•×Ÿ ×‘× ×ª×•× ×™×")
            
        current_lookback_days = config.initial_lookback_days
        previous_best_accuracy = 0.0
        
        for iteration in range(1, config.max_iterations + 1):
            self.logger.info(f"\nğŸ”„ ××™×˜×¨×¦×™×” #{iteration}")
            
            try:
                # ×©×œ×‘ 1: ×—×™×©×•×‘ ×ª××¨×™×›×™ ××™××•×Ÿ ×•×‘×“×™×§×”
                training_cutoff, validation_start, validation_end = self._calculate_dates(
                    latest_date, current_lookback_days
                )
                
                self.logger.info(f"ğŸ“… ××™××•×Ÿ ×¢×“: {training_cutoff}")
                self.logger.info(f"ğŸ“… ×‘×“×™×§×”: {validation_start} â†’ {validation_end}")
                
                # ×©×œ×‘ 2: ××™××•×Ÿ ××•×“×œ×™×
                models_trained = self._train_models_for_iteration(
                    training_cutoff, config.horizons, iteration
                )
                
                if not models_trained:
                    self.logger.error("âŒ ×›×©×œ×•×Ÿ ×‘××™××•×Ÿ ××•×“×œ×™×")
                    break
                    
                # ×©×œ×‘ 3: ×™×¦×™×¨×ª ×ª×—×–×™×•×ª ×¢×œ ×ª×§×•×¤×ª ×”×‘×“×™×§×”
                predictions = self._generate_predictions(
                    models_trained, validation_start, validation_end
                )
                
                # ×©×œ×‘ 4: ××™×¡×•×£ ×ª×•×¦××•×ª ×‘×¤×•×¢×œ
                actual_results = self._collect_actual_results(
                    predictions, validation_start, validation_end, label_threshold=config.label_threshold
                )
                
                # ×©×œ×‘ 5: ×”×©×•×•××” ×•×—×™×©×•×‘ ×“×™×•×§
                accuracy_by_horizon = self._calculate_accuracy(
                    predictions, actual_results, config.horizons, blend_alpha=config.blend_alpha
                )
                
                # ×©×œ×‘ 6: ×‘×“×™×§×ª ×©×™×¤×•×¨
                avg_accuracy = sum(accuracy_by_horizon.values()) / len(accuracy_by_horizon)
                improvement = avg_accuracy - previous_best_accuracy
                
                # ×©××™×¨×ª ×ª×•×¦××•×ª ××™×˜×¨×¦×™×”
                iteration_result = IterativeResults(
                    iteration=iteration,
                    training_cutoff_date=training_cutoff,
                    validation_start_date=validation_start,
                    validation_end_date=validation_end,
                    models_trained=models_trained,
                    predictions=predictions,
                    actual_results=actual_results,
                    accuracy_by_horizon=accuracy_by_horizon,
                    improvement_from_previous=improvement if iteration > 1 else None
                )
                
                self.results_history.append(iteration_result)
                self._save_iteration_results(iteration_result)
                
                # ×“×™×•×•×— ×ª×•×¦××•×ª
                self.logger.info(f"ğŸ“Š ×“×™×•×§ ×××•×¦×¢: {avg_accuracy:.3f}")
                self.logger.info(f"ğŸ“ˆ ×©×™×¤×•×¨: {improvement:.3f}" if iteration > 1 else "ğŸ“ˆ ××™×˜×¨×¦×™×” ×¨××©×•× ×”")
                
                for horizon, acc in accuracy_by_horizon.items():
                    self.logger.info(f"   {horizon}D: {acc:.3f}")
                
                # ×‘×“×™×§×ª ×ª× ××™ ×¢×¦×™×¨×”
                if avg_accuracy >= config.target_accuracy:
                    self.logger.info(f"ğŸ¯ ×”×’×¢× ×• ×œ×“×™×•×§ ×™×¢×“ ({config.target_accuracy:.3f})!")
                    break
                    
                if iteration > 1 and improvement < config.min_accuracy_improvement:
                    self.logger.info(f"ğŸ“‰ ×©×™×¤×•×¨ ×§×˜×Ÿ ××“×™ ({improvement:.3f} < {config.min_accuracy_improvement:.3f})")
                    break
                
                # ×”×›× ×” ×œ××™×˜×¨×¦×™×” ×”×‘××” - ×”×•×¡×¤×ª ×™×•×ª×¨ × ×ª×•× ×™×
                previous_best_accuracy = max(previous_best_accuracy, avg_accuracy)
                current_lookback_days += 5  # ×”×•×¡×£ 5 ×™××™ ××¡×—×¨ × ×•×¡×¤×™×
                
            except Exception as e:
                self.logger.error(f"âŒ ×©×’×™××” ×‘××™×˜×¨×¦×™×” #{iteration}: {e}")
                break
                
        self.logger.info(f"âœ… ××™××•×Ÿ ×˜×™×˜×¨×˜×™×‘×™ ×”×•×©×œ× ××—×¨×™ {len(self.results_history)} ××™×˜×¨×¦×™×•×ª")
        return self.results_history
    
    def _calculate_dates(self, latest_date: pd.Timestamp, lookback_days: int) -> Tuple[str, str, str]:
        """×—×™×©×•×‘ ×ª××¨×™×›×™ ××™××•×Ÿ ×•×‘×“×™×§×”"""
        
        # ×ª××¨×™×š ×’×‘×•×œ ×œ××™××•×Ÿ (lookback_days ×™××™ ××¡×—×¨ ××—×•×¨×”)
        business_days = pd.bdate_range(end=latest_date, periods=lookback_days + 1, freq='B')
        training_cutoff = business_days[0].strftime('%Y-%m-%d')
        
        # ×ª×§×•×¤×ª ×‘×“×™×§×” - ××ª××¨×™×š ×”×’×‘×•×œ ×¢×“ ×”×ª××¨×™×š ×”××—×¨×•×Ÿ
        validation_start = business_days[1].strftime('%Y-%m-%d')  # ×™×•× ××—×¨×™ ×”×’×‘×•×œ
        validation_end = latest_date.strftime('%Y-%m-%d')
        
        return training_cutoff, validation_start, validation_end
    
    def _find_latest_date(self) -> Optional[pd.Timestamp]:
        """××¦×™××ª ×”×ª××¨×™×š ×”××—×¨×•×Ÿ ×‘× ×ª×•× ×™×"""
        latest = None
        
        for symbol, df in self.data_map.items():
            if df is None or df.empty:
                continue
                
            try:
                if isinstance(df.index, pd.DatetimeIndex):
                    df_latest = df.index.max()
                elif 'Date' in df.columns:
                    df_latest = pd.to_datetime(df['Date']).max()
                else:
                    continue
                    
                if latest is None or df_latest > latest:
                    latest = df_latest
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ ×‘×¢×™×” ×‘×¢×™×‘×•×“ ×ª××¨×™×š ×¢×‘×•×¨ {symbol}: {e}")
                continue
                
        return latest
    
    def _train_models_for_iteration(self, cutoff_date: str, horizons: List[int], iteration: int) -> Dict[int, str]:
        """××™××•×Ÿ ××•×“×œ×™× ×œ××™×˜×¨×¦×™×” ×¡×¤×¦×™×¤×™×ª"""
        
        # ×™×™×‘×•× ×”×¤×•× ×§×¦×™×•×ª ××”××¢×¨×›×ª ×”×§×™×™××ª
        from ml.train_model import filter_data_until_date, train_multi_horizon_model
        
        self.logger.info(f"ğŸ§  ××××Ÿ ××•×“×œ×™× ×œ××™×˜×¨×¦×™×” #{iteration}")
        
        # ×¡×™× ×•×Ÿ × ×ª×•× ×™× ×¢×“ ×ª××¨×™×š ×”×’×‘×•×œ
        filtered_data = filter_data_until_date(self.data_map, cutoff_date)
        
        if not filtered_data:
            self.logger.error("âŒ ×œ× × ××¦××• × ×ª×•× ×™× ××¡×•× × ×™×")
            return {}
            
        models_trained = {}
        
        for horizon in horizons:
            try:
                self.logger.info(f"  ğŸ“š ××××Ÿ ××•×“×œ {horizon}D...")
                
                model_path = train_multi_horizon_model(
                    cutoff_date=cutoff_date,
                    horizon_days=horizon,
                    algorithm='rf',  # ×›×¨×’×¢ ×¨×§ RF, ××¤×©×¨ ×œ×”×¨×—×™×‘
                    data_map=filtered_data
                )
                
                if model_path and os.path.exists(model_path):
                    models_trained[horizon] = model_path
                    self.logger.info(f"    âœ… {horizon}D: {model_path}")
                else:
                    self.logger.warning(f"    âŒ {horizon}D: ×›×©×œ×•×Ÿ ×‘××™××•×Ÿ")
                    
            except Exception as e:
                self.logger.error(f"    âŒ {horizon}D: {e}")
                
        return models_trained
    
    def _generate_predictions(self, models: Dict[int, str], start_date: str, end_date: str) -> List[Dict]:
        """×™×¦×™×¨×ª ×ª×—×–×™×•×ª ×œ×ª×§×•×¤×ª ×”×‘×“×™×§×”"""
        
        self.logger.info(f"ğŸ”® ×™×•×¦×¨ ×ª×—×–×™×•×ª {start_date} â†’ {end_date}")
        
        # ×™×™×‘×•× ×”×¤×•× ×§×¦×™×•×ª ×”× ×“×¨×©×•×ª
        from ml.train_model import load_model
        from ml.feature_engineering import compute_features
        import pandas as pd
        
        predictions = []
        
        # ××™×˜×¨×¦×™×” ×¢×œ ×ª××¨×™×›×™× ×¢×¡×§×™×™× ×‘×ª×§×•×¤×ª ×”×‘×“×™×§×”
        date_range = pd.bdate_range(start=start_date, end=end_date, freq='B')
        
        for current_date in date_range:
            date_str = current_date.strftime('%Y-%m-%d')
            
            # ××™×˜×¨×¦×™×” ×¢×œ ×›×œ ×× ×™×”
            for symbol, df in self.data_map.items():
                if df is None or df.empty:
                    continue
                    
                try:
                    # ×¡×™× ×•×Ÿ × ×ª×•× ×™× ×¢×“ ×”×ª××¨×™×š ×”× ×•×›×—×™
                    # ×•×™×“×•× ×©×”××™× ×“×§×¡ ×”×•× datetime
                    if not pd.api.types.is_datetime64_any_dtype(df.index):
                        df.index = pd.to_datetime(df.index, utc=True)
                    
                    # ×•×™×“×•× ×©×”-current_date ×”×•× timezone-aware ×× ×”× ×ª×•× ×™× timezone-aware
                    if df.index.tz is not None and current_date.tz is None:
                        current_date = current_date.tz_localize('UTC')
                    elif df.index.tz is None and current_date.tz is not None:
                        current_date = current_date.tz_localize(None)
                    
                    df_until_date = df[df.index <= current_date]
                    
                    if len(df_until_date) < 50:  # ××™× ×™××•× × ×ª×•× ×™×
                        continue
                        
                    # ×—×™×©×•×‘ features ×œ×ª××¨×™×š ×”× ×•×›×—×™
                    features_df = compute_features(df_until_date)
                    
                    if features_df.empty:
                        continue
                        
                    # ×§×‘×œ×ª ×”×¨×©×•××” ×”××—×¨×•× ×” (×”×ª××¨×™×š ×”× ×•×›×—×™)
                    latest_features = features_df.iloc[-1:].drop(columns=['label'], errors='ignore')
                    
                    # ×”×¨×¦×ª ×ª×—×–×™×•×ª ×œ×›×œ horizon
                    for horizon, model_path in models.items():
                        if not os.path.exists(model_path):
                            continue
                            
                        try:
                            model_obj = load_model(model_path)
                            if model_obj is None:
                                continue
                            
                            # ×”××•×“×œ × ×©××¨ ×›-dictionary ×¢× ××¤×ª×— 'model'
                            if isinstance(model_obj, dict) and 'model' in model_obj:
                                model = model_obj['model']
                            else:
                                model = model_obj
                                
                            # ×ª×—×–×™×ª
                            prediction_proba = model.predict_proba(latest_features)[0]
                            prediction_class = model.predict(latest_features)[0]
                            
                            # ×©××™×¨×ª ×”×ª×—×–×™×ª
                            predictions.append({
                                'date': date_str,
                                'symbol': symbol,
                                'horizon': horizon,
                                'prediction_class': int(prediction_class),
                                'prediction_proba': float(prediction_proba[1]),  # ×”×¡×ª×‘×¨×•×ª ×œ×›×™×•×•×Ÿ ×—×™×•×‘×™
                                'current_price': float(df_until_date['Close'].iloc[-1]),
                                'target_date': (current_date + pd.Timedelta(days=horizon)).strftime('%Y-%m-%d')
                            })
                            
                        except Exception as e:
                            self.logger.warning(f"âš ï¸ ×ª×—×–×™×ª × ×›×©×œ×” {symbol} {horizon}D {date_str}: {e}")
                            
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ×¢×™×‘×•×“ × ×›×©×œ {symbol} {date_str}: {e}")
        
        self.logger.info(f"âœ… × ×•×¦×¨×• {len(predictions)} ×ª×—×–×™×•×ª")
        return predictions
    
    def _collect_actual_results(self, predictions: List[Dict], start_date: str, end_date: str, label_threshold: float = 0.02) -> List[Dict]:
        """××™×¡×•×£ ×ª×•×¦××•×ª ×‘×¤×•×¢×œ ×œ××•×ª×Ÿ ×”×ª×—×–×™×•×ª"""
        
        self.logger.info(f"ğŸ“Š ××•×¡×£ ×ª×•×¦××•×ª ×‘×¤×•×¢×œ {start_date} â†’ {end_date}")
        
        actual_results = []
        
        for prediction in predictions:
            try:
                symbol = prediction['symbol']
                target_date = prediction['target_date']
                horizon = prediction['horizon']
                current_price = prediction['current_price']
                
                # ×‘×“×™×§×” ×©×™×© ×œ× ×• × ×ª×•× ×™× ×œ×× ×™×”
                if symbol not in self.data_map or self.data_map[symbol] is None:
                    continue
                    
                df = self.data_map[symbol]
                
                # ×—×™×¤×•×© ×”××—×™×¨ ×‘×ª××¨×™×š ×”×™×¢×“
                import pandas as pd
                target_dt = pd.to_datetime(target_date)
                
                # ×•×™×“×•× ×©×”××™× ×“×§×¡ ×”×•× datetime
                if not pd.api.types.is_datetime64_any_dtype(df.index):
                    df.index = pd.to_datetime(df.index, utc=True)
                
                # ×•×™×“×•× timezone consistency
                if df.index.tz is not None and target_dt.tz is None:
                    target_dt = target_dt.tz_localize('UTC')
                elif df.index.tz is None and target_dt.tz is not None:
                    target_dt = target_dt.tz_localize(None)
                
                # ××¦×™××ª ×”×ª××¨×™×š ×”×§×¨×•×‘ ×‘×™×•×ª×¨ (×‘××§×¨×” ×©×œ ×¡×•×£ ×©×‘×•×¢/×—×’×™×)
                available_dates = df.index[df.index >= target_dt]
                
                if len(available_dates) == 0:
                    # ××™×Ÿ × ×ª×•× ×™× ×œ×ª××¨×™×š ×”×™×¢×“ - ××•×œ×™ ×”×ª×—×–×™×ª ×¢×“×™×™×Ÿ ×‘×¢×ª×™×“
                    continue
                    
                actual_date = available_dates[0]
                actual_price = float(df.loc[actual_date, 'Close'])
                
                # ×—×™×©×•×‘ ×”×ª×©×•××” ×‘×¤×•×¢×œ
                actual_return = (actual_price - current_price) / current_price
                
                # ×©×™××•×© ×‘-threshold ×“×™× ××™ ××”×§×•× ×¤×™×’
                actual_direction = 1 if actual_return >= label_threshold else 0
                
                # ×‘×“×™×§×” ×”×× ×”×ª×—×–×™×ª ×”×™×™×ª×” × ×›×•× ×”
                prediction_correct = (prediction['prediction_class'] == actual_direction)
                
                actual_results.append({
                    'date': prediction['date'],
                    'symbol': symbol,
                    'horizon': horizon,
                    'prediction_class': prediction['prediction_class'],
                    'prediction_proba': prediction['prediction_proba'],
                    'actual_class': actual_direction,
                    'actual_return': actual_return,
                    'current_price': current_price,
                    'actual_price': actual_price,
                    'target_date': target_date,
                    'actual_date': actual_date.strftime('%Y-%m-%d'),
                    'prediction_correct': prediction_correct
                })
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ××™×¡×•×£ ×ª×•×¦××•×ª × ×›×©×œ ×¢×‘×•×¨ {prediction.get('symbol', 'unknown')}: {e}")
        
        self.logger.info(f"âœ… × ××¡×¤×• {len(actual_results)} ×ª×•×¦××•×ª ×‘×¤×•×¢×œ")
        return actual_results
    
    def _calculate_accuracy(self, predictions: List[Dict], actual_results: List[Dict], horizons: List[int], blend_alpha: float = 0.40) -> Dict[int, float]:
        """×—×™×©×•×‘ ×“×™×•×§ ×œ×›×œ horizon"""
        
        accuracy_by_horizon = {}
        
        for horizon in horizons:
            # ×¡×™× ×•×Ÿ ×ª×•×¦××•×ª ×œ××•×¤×§ ×”×¡×¤×¦×™×¤×™
            horizon_results = [r for r in actual_results if r['horizon'] == horizon]
            
            if not horizon_results:
                accuracy_by_horizon[horizon] = 0.0
                continue
                
            # ×—×™×©×•×‘ ×“×™×•×§ ×‘×¡×™×¡×™
            correct_predictions = sum(1 for r in horizon_results if r['prediction_correct'])
            total_predictions = len(horizon_results)
            
            basic_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
            
            # ×—×™×©×•×‘ ×“×™×•×§ ××©×•×§×œ×œ ×œ×¤×™ ×¨××ª ×‘×™×˜×—×•×Ÿ
            # ×ª×—×–×™×•×ª ×¢× ×”×¡×ª×‘×¨×•×ª ×’×‘×•×”×” ×™×•×ª×¨ ××§×‘×œ×•×ª ××©×§×œ ×’×‘×•×” ×™×•×ª×¨
            weighted_correct = 0.0
            weighted_total = 0.0
            
            for result in horizon_results:
                confidence = abs(result['prediction_proba'] - 0.5) * 2  # 0 = ××™×Ÿ ×‘×™×˜×—×•×Ÿ, 1 = ×‘×™×˜×—×•×Ÿ ××œ×
                weight = max(0.1, confidence)  # ××©×§×œ ××™× ×™××œ×™ ×©×œ 0.1
                
                weighted_total += weight
                if result['prediction_correct']:
                    weighted_correct += weight
            
            weighted_accuracy = weighted_correct / weighted_total if weighted_total > 0 else 0.0
            
            # ×”×’×‘×œ×ª blend_alpha
            try:
                ba = max(0.0, min(1.0, float(blend_alpha)))
            except Exception:
                ba = 0.40
            # ×©×™×œ×•×‘: basic*(1-alpha) + weighted*alpha
            final_accuracy = (basic_accuracy * (1.0 - ba)) + (weighted_accuracy * ba)
            
            accuracy_by_horizon[horizon] = final_accuracy
            
            # ×œ×•×’ ××¤×•×¨×˜
            self.logger.info(
                f"  {horizon}D: {correct_predictions}/{total_predictions} = {basic_accuracy:.3f} "
                f"(weighted: {weighted_accuracy:.3f}, final: {final_accuracy:.3f}, Î±={ba:.2f})"
            )
            
        return accuracy_by_horizon
    
    def _save_iteration_results(self, result: IterativeResults):
        """×©××™×¨×ª ×ª×•×¦××•×ª ××™×˜×¨×¦×™×”"""
        
        filename = f"iteration_{result.iteration:02d}_{result.training_cutoff_date.replace('-', '')}.json"
        filepath = os.path.join(self.results_dir, filename)
        
        # ×”××¨×” ×œ-dict ×œ×©××™×¨×”
        result_dict = {
            'iteration': result.iteration,
            'training_cutoff_date': result.training_cutoff_date,
            'validation_start_date': result.validation_start_date,
            'validation_end_date': result.validation_end_date,
            'models_trained': result.models_trained,
            'predictions_count': len(result.predictions),
            'actual_results_count': len(result.actual_results),
            'accuracy_by_horizon': result.accuracy_by_horizon,
            'improvement_from_previous': result.improvement_from_previous,
            'horizons': list(result.accuracy_by_horizon.keys()),
            'avg_accuracy': (sum(result.accuracy_by_horizon.values()) / len(result.accuracy_by_horizon)) if result.accuracy_by_horizon else 0.0
        }
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result_dict, f, ensure_ascii=False, indent=2)
            # ×©××™×¨×ª ×¤×™×¨×•×˜ ××œ× ×©×œ ×ª×•×¦××•×ª actual (×›×•×œ×œ ×”×¡×ª×‘×¨×•×ª ×•×“×™×•×§ ×œ×›×œ ×ª×—×–×™×ª)
            if result.actual_results:
                detailed_path = filepath.replace('.json', '_actual_results.json')
                with open(detailed_path, 'w', encoding='utf-8') as df:
                    json.dump(result.actual_results, df, ensure_ascii=False, indent=2)
            # ××•×¤×¦×™×•× ×œ×™: ×©××™×¨×ª ×ª×—×–×™×•×ª (×œ×œ× actual ×× ×—×¡×¨)
            if result.predictions:
                preds_path = filepath.replace('.json', '_predictions.json')
                with open(preds_path, 'w', encoding='utf-8') as pf:
                    json.dump(result.predictions, pf, ensure_ascii=False, indent=2)
            self.logger.info(f"ğŸ’¾ × ×©××¨×• ×§×‘×¦×™ ××™×˜×¨×¦×™×”: {filepath}")
        except Exception as e:
            self.logger.error(f"âŒ ×›×©×œ×•×Ÿ ×‘×©××™×¨×ª ×ª×•×¦××•×ª: {e}")

def demo_iterative_training():
    """×”×“××™×” ×©×œ ×”×¤×•× ×§×¦×™×•× ×œ×™×•×ª ×”×—×“×©×”"""
    
    print("ğŸ”„ Demo: Iterative Historical Training")
    print("=" * 50)
    
    # ×˜×¢×™× ×ª × ×ª×•× ×™× (×“××”)
    print("ğŸ“Š Loading demo data...")
    
    # ×‘×¤×•×¢×œ ×›××Ÿ × ×˜×¢×Ÿ data_map ×××™×ª×™
    data_map = {}  # placeholder
    
    if not data_map:
        print("âš ï¸ No data loaded - this is just a demo")
        return
        
    # ×”×’×“×¨×ª ×ª×¦×•×¨×”
    config = IterativeTrainingConfig(
        initial_lookback_days=30,
        horizons=[1, 5, 10],
        max_iterations=5,
        min_accuracy_improvement=0.01,
        target_accuracy=0.70
    )
    
    # ×™×¦×™×¨×ª ××¢×¨×›×ª ××™××•×Ÿ
    trainer = IterativeHistoricalTrainer(data_map)
    
    # ×”×¨×¦×ª ×”×ª×”×œ×™×š
    results = trainer.run_iterative_training(config)
    
    # ×”×¦×’×ª ×ª×•×¦××•×ª
    print(f"\nğŸ“‹ ×ª×•×¦××•×ª ×¡×•×¤×™×•×ª: {len(results)} ××™×˜×¨×¦×™×•×ª")
    
    for i, result in enumerate(results, 1):
        print(f"\n××™×˜×¨×¦×™×” #{i}:")
        print(f"  ğŸ“… ××™××•×Ÿ ×¢×“: {result.training_cutoff_date}")
        print(f"  ğŸ“Š ×“×™×•×§ ×××•×¦×¢: {sum(result.accuracy_by_horizon.values()) / len(result.accuracy_by_horizon):.3f}")
        if result.improvement_from_previous:
            print(f"  ğŸ“ˆ ×©×™×¤×•×¨: {result.improvement_from_previous:.3f}")

if __name__ == "__main__":
    demo_iterative_training()