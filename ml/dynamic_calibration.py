"""
Live Performance Tracking & Dynamic Calibration

×”×¨×¢×™×•×Ÿ: ×œ×§×—×ª ×ª×—×–×™×•×ª ××œ×¤× ×™ 5-10 ×™××™×, ×œ×‘×“×•×§ ××™×š ×”×Ÿ ×”×ª×××©×•,
×•×œ×”×©×ª××© ×‘×–×” ×œ×›×•×•× ×•×Ÿ ×“×™× ××™ ×©×œ ×”×¡×¨×™×§×”.

Implementation Plan:
1. Live Validation: ×‘×“×™×§×ª ×ª×—×–×™×•×ª ×‘×–××Ÿ ×××ª
2. Dynamic Thresholds: ×¢×“×›×•×Ÿ ×¡×¤×™× ×‘××•×¤×Ÿ ××•×˜×•××˜×™  
3. Adaptive Scoring: ×”×ª×××ª ××©×§×œ×™× ×‘×¦×™×•×Ÿ ×”××¨×•×›×‘
4. Performance Feedback: ××ª×Ÿ ××©×•×‘ ×œ××©×ª××© ×¢×œ ××™×›×•×ª ×”×—×–××™
"""

import os
import json
import datetime
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

@dataclass
class LivePerformance:
    """Live performance metrics for recent predictions"""
    total_predictions: int
    correct_5d: int
    correct_10d: int
    accuracy_5d: float
    accuracy_10d: float
    avg_ml_prob: float
    confidence_score: float

class DynamicCalibrator:
    """
    ××¢×¨×›×ª ×›×™×•×œ ×“×™× ××™×ª ×©×‘×•×“×§×ª ×‘×™×¦×•×¢×™× ×‘×–××Ÿ ×××ª
    ×•××ª××™××” ××ª ×¤×¨××˜×¨×™ ×”×¡×¨×™×§×” ×‘×”×ª××
    """
    
    def __init__(self, pred_log_path: str = "ml/predictions.jsonl"):
        self.pred_log_path = pred_log_path
        self.min_samples = 10  # ××¡×¤×¨ ××™× ×™××œ×™ ×©×œ ×“×’×™××•×ª ×œ×›×™×•×œ
        
    def check_recent_performance(self, days_back: int = 10) -> Optional[LivePerformance]:
        """
        ×‘×“×™×§×ª ×‘×™×¦×•×¢×™× ×©×œ ×ª×—×–×™×•×ª ××”×™××™× ×”××—×¨×•× ×™×
        """
        if not os.path.exists(self.pred_log_path):
            return None
            
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days_back)
        recent_preds = []
        
        # ×§×¨×™××ª ×”×ª×—×–×™×•×ª ×”×¨×œ×•×•× ×˜×™×•×ª
        with open(self.pred_log_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    rec = json.loads(line.strip())
                    pred_date = datetime.datetime.strptime(rec.get('date', ''), '%Y-%m-%d')
                    if pred_date >= cutoff_date and 'realized' in rec:
                        recent_preds.append(rec)
                except Exception:
                    continue
        
        if len(recent_preds) < self.min_samples:
            return None
            
        # ×—×™×©×•×‘ ××˜×¨×™×§×•×ª
        total = len(recent_preds)
        correct_5d = sum(1 for p in recent_preds 
                        if p.get('realized', {}).get('5d') == 1)
        correct_10d = sum(1 for p in recent_preds 
                         if p.get('realized', {}).get('10d') == 1)
        
        accuracy_5d = correct_5d / total
        accuracy_10d = correct_10d / total
        avg_ml_prob = sum(p.get('prob', 0) for p in recent_preds) / total
        
        # ×¦×™×•×Ÿ ×××™× ×•×ª - ×›××” ×”×—×–××™ ×¢×§×‘×™
        confidence_score = min(accuracy_5d, accuracy_10d) * (total / 20)  # normalized
        
        return LivePerformance(
            total_predictions=total,
            correct_5d=correct_5d,
            correct_10d=correct_10d,
            accuracy_5d=accuracy_5d,
            accuracy_10d=accuracy_10d,
            avg_ml_prob=avg_ml_prob,
            confidence_score=min(confidence_score, 1.0)
        )
    
    def suggest_threshold_adjustment(self, performance: LivePerformance) -> Dict[str, Any]:
        """
        ×”×¦×¢×ª ×”×ª×××•×ª ×œ×¤×¨××˜×¨×™ ×”×¡×¨×™×§×” ×¢×œ ×‘×¡×™×¡ ×”×‘×™×¦×•×¢×™×
        """
        adjustments = {
            'ml_threshold_adjustment': 0.0,
            'score_weight_adjustments': {},
            'confidence_level': 'medium',
            'recommendations': []
        }
        
        # ×”×ª×××ª ×¡×£ ML
        if performance.accuracy_5d < 0.4:  # ×‘×™×¦×•×¢×™× ×—×œ×©×™×
            adjustments['ml_threshold_adjustment'] = 0.1  # ×”×¢×œ×” ×¡×£
            adjustments['recommendations'].append("×‘×™×¦×•×¢×™× ×—×œ×©×™× - ××¢×œ×” ×¡×£ ML ×œ-0.6+")
            adjustments['confidence_level'] = 'low'
        elif performance.accuracy_5d > 0.7:  # ×‘×™×¦×•×¢×™× ××¢×•×œ×™×
            adjustments['ml_threshold_adjustment'] = -0.05  # ×”×•×¨×“ ×¡×£ ××¢×˜
            adjustments['recommendations'].append("×‘×™×¦×•×¢×™× ××¢×•×œ×™× - ××•×¨×™×“ ×¡×£ ML ×œ-0.45")
            adjustments['confidence_level'] = 'high'
        
        # ×”×ª×××ª ××©×§×œ×™× ×‘×¦×™×•×Ÿ
        if performance.accuracy_5d > performance.accuracy_10d + 0.1:
            # 5 ×™××™× ×¢×•×‘×“ ×™×•×ª×¨ ×˜×•×‘
            adjustments['score_weight_adjustments'] = {
                'w_prob': 0.60,  # ×ª×Ÿ ×™×•×ª×¨ ××©×§×œ ×œ-ML
                'w_rr': 0.20,
                'w_fresh': 0.15,
                'w_pattern': 0.05
            }
            adjustments['recommendations'].append("×ª×—×–×™×ª ×§×¦×¨×ª ×˜×•×•×— ×™×•×ª×¨ ××“×•×™×§×ª - ××’×‘×™×¨ ××©×§×œ ML")
        
        return adjustments
    
    def get_calibration_report(self) -> str:
        """
        ×“×•×— ×›×™×•×œ ×¢× ×”××œ×¦×•×ª ×œ×©×™×¤×•×¨
        """
        performance = self.check_recent_performance()
        if not performance:
            return "âŒ ××™×Ÿ ××¡×¤×™×§ × ×ª×•× ×™× ×œ×›×™×•×œ (× ×“×¨×©×•×ª ×œ×¤×—×•×ª 10 ×ª×—×–×™×•×ª)"
        
        adjustments = self.suggest_threshold_adjustment(performance)
        
        report = f"""
ğŸ“Š **×“×•×— ×›×™×•×œ ×“×™× ××™**

**×‘×™×¦×•×¢×™× ××—×¨×•× ×™× ({performance.total_predictions} ×ª×—×–×™×•×ª):**
â€¢ ×“×™×•×§ 5 ×™××™×: {performance.accuracy_5d:.1%} ({performance.correct_5d}/{performance.total_predictions})
â€¢ ×“×™×•×§ 10 ×™××™×: {performance.accuracy_10d:.1%} ({performance.correct_10d}/{performance.total_predictions})
â€¢ ×”×¡×ª×‘×¨×•×ª ×××•×¦×¢×ª: {performance.avg_ml_prob:.3f}
â€¢ ×¦×™×•×Ÿ ×××™× ×•×ª: {performance.confidence_score:.2f}/1.0

**×¨××ª ×××™× ×•×ª: {adjustments['confidence_level'].upper()}**

**×”××œ×¦×•×ª:**
{chr(10).join('â€¢ ' + rec for rec in adjustments['recommendations'])}

**×”×ª×××•×ª ××•×¦×¢×•×ª:**
â€¢ ×¡×£ ML: {adjustments['ml_threshold_adjustment']:+.3f}
â€¢ ××©×§×œ×™ ×¦×™×•×Ÿ: {adjustments.get('score_weight_adjustments', '×œ×œ× ×©×™× ×•×™')}
"""
        
        return report

def integrate_with_scanning(scan_params: Dict[str, Any]) -> Dict[str, Any]:
    """
    ×©×™×œ×•×‘ ×”×›×™×•×œ ×”×“×™× ××™ ×¢× ×¤×¨××˜×¨×™ ×”×¡×¨×™×§×”
    """
    calibrator = DynamicCalibrator()
    performance = calibrator.check_recent_performance()
    
    if performance and performance.total_predictions >= 10:
        adjustments = calibrator.suggest_threshold_adjustment(performance)
        
        # ×¢×“×›×•×Ÿ ×¤×¨××˜×¨×™×
        current_threshold = scan_params.get('ml_min_prob', 0.5)
        new_threshold = max(0.3, min(0.8, 
            current_threshold + adjustments['ml_threshold_adjustment']))
        
        scan_params['ml_min_prob'] = new_threshold
        
        # ×¢×“×›×•×Ÿ ××©×§×œ×™× ×× ×™×© ×”××œ×¦×”
        if adjustments.get('score_weight_adjustments'):
            scan_params.update(adjustments['score_weight_adjustments'])
        
        # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×”×›×™×•×œ
        scan_params['_calibration_info'] = {
            'performance': performance,
            'adjustments_applied': adjustments,
            'calibration_timestamp': datetime.datetime.now().isoformat()
        }
    
    return scan_params

if __name__ == "__main__":
    # ×“××• ×©×œ ×”××¢×¨×›×ª
    calibrator = DynamicCalibrator()
    print(calibrator.get_calibration_report())
    
    # ×“××• ×©×œ ×©×™×œ×•×‘ ×¢× ×¡×¨×™×§×”
    sample_params = {
        'ml_min_prob': 0.5,
        'w_prob': 0.55,
        'w_rr': 0.25,
        'w_fresh': 0.15,
        'w_pattern': 0.05
    }
    
    print("\n" + "="*50)
    print("×¤×¨××˜×¨×™× ×œ×¤× ×™ ×›×™×•×œ:", sample_params)
    
    updated_params = integrate_with_scanning(sample_params)
    print("×¤×¨××˜×¨×™× ××—×¨×™ ×›×™×•×œ:", updated_params)